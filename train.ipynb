{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnE1_J-4dhSR"
   },
   "source": [
    "## Загрузим нужные библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uaKzqUxsdjDa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /home/gennalll/.local/lib/python3.8/site-packages (1.1.1)\n",
      "Requirement already satisfied: graphviz in /home/gennalll/.local/lib/python3.8/site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (from catboost) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/gennalll/.local/lib/python3.8/site-packages (from catboost) (1.23.3)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /home/gennalll/.local/lib/python3.8/site-packages (from catboost) (1.4.1)\n",
      "Requirement already satisfied: scipy in /home/gennalll/.local/lib/python3.8/site-packages (from catboost) (1.8.0)\n",
      "Requirement already satisfied: plotly in /home/gennalll/.local/lib/python3.8/site-packages (from catboost) (5.10.0)\n",
      "Requirement already satisfied: six in /home/gennalll/.local/lib/python3.8/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/gennalll/.local/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gennalll/.local/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2021.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/gennalll/.local/lib/python3.8/site-packages (from plotly->catboost) (8.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 19:53:41.711161: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-10 19:53:41.850880: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-10 19:53:41.850903: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-10 19:53:41.888208: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-10 19:53:42.569045: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-10 19:53:42.569117: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-10 19:53:42.569126: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import uniform\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.over_sampling import BorderlineSMOTE \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn import svm\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import catboost as cb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>oper_type + oper_attr</th>\n",
       "      <th>index_oper</th>\n",
       "      <th>type</th>\n",
       "      <th>priority</th>\n",
       "      <th>is_privatecategory</th>\n",
       "      <th>class</th>\n",
       "      <th>is_in_yandex</th>\n",
       "      <th>is_return</th>\n",
       "      <th>weight</th>\n",
       "      <th>mailtype</th>\n",
       "      <th>mailctg</th>\n",
       "      <th>mailrank</th>\n",
       "      <th>directctg</th>\n",
       "      <th>transport_pay</th>\n",
       "      <th>postmark</th>\n",
       "      <th>name_mfi</th>\n",
       "      <th>weight_mfi</th>\n",
       "      <th>price_mfi</th>\n",
       "      <th>dist_qty_oper_login_1</th>\n",
       "      <th>total_qty_oper_login_1</th>\n",
       "      <th>total_qty_oper_login_0</th>\n",
       "      <th>total_qty_over_index_and_type</th>\n",
       "      <th>total_qty_over_index</th>\n",
       "      <th>is_wrong_sndr_name</th>\n",
       "      <th>is_wrong_rcpn_name</th>\n",
       "      <th>is_wrong_phone_number</th>\n",
       "      <th>is_wrong_address</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6818780</td>\n",
       "      <td>26</td>\n",
       "      <td>17235</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46654</td>\n",
       "      <td>41.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>720176.0</td>\n",
       "      <td>58950.0</td>\n",
       "      <td>779126.0</td>\n",
       "      <td>8290896.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9907176</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>194484</td>\n",
       "      <td>68.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>914.0</td>\n",
       "      <td>48856658.0</td>\n",
       "      <td>83318932.0</td>\n",
       "      <td>132175590.0</td>\n",
       "      <td>136819803.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3304275</td>\n",
       "      <td>15</td>\n",
       "      <td>16331</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92224</td>\n",
       "      <td>56.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3246292.0</td>\n",
       "      <td>3233068.0</td>\n",
       "      <td>6479360.0</td>\n",
       "      <td>52708071.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9020937</td>\n",
       "      <td>16</td>\n",
       "      <td>6325</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>416.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79671</td>\n",
       "      <td>33.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2060928.0</td>\n",
       "      <td>653280.0</td>\n",
       "      <td>2714208.0</td>\n",
       "      <td>19562334.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3082311</td>\n",
       "      <td>17</td>\n",
       "      <td>17315</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>795.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141303</td>\n",
       "      <td>716.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>316919.0</td>\n",
       "      <td>27911.0</td>\n",
       "      <td>344830.0</td>\n",
       "      <td>4719186.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999995</th>\n",
       "      <td>9958614</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63431</td>\n",
       "      <td>24.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>64270133.0</td>\n",
       "      <td>116432632.0</td>\n",
       "      <td>180702765.0</td>\n",
       "      <td>188407812.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999996</th>\n",
       "      <td>2234489</td>\n",
       "      <td>19</td>\n",
       "      <td>4697</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36730</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1832.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1767370.0</td>\n",
       "      <td>144063.0</td>\n",
       "      <td>1911433.0</td>\n",
       "      <td>15582018.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999997</th>\n",
       "      <td>4304572</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>94.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37295</td>\n",
       "      <td>952.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>60613352.0</td>\n",
       "      <td>10648.0</td>\n",
       "      <td>60624000.0</td>\n",
       "      <td>75592387.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999998</th>\n",
       "      <td>6550634</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>15091338.0</td>\n",
       "      <td>4972424.0</td>\n",
       "      <td>20063762.0</td>\n",
       "      <td>39988530.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999999</th>\n",
       "      <td>6423388</td>\n",
       "      <td>99</td>\n",
       "      <td>751</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62590</td>\n",
       "      <td>40.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1541.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>1894.0</td>\n",
       "      <td>17238.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000000 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  oper_type + oper_attr  index_oper  type  priority  \\\n",
       "0        6818780                     26       17235    18         1   \n",
       "1        9907176                     20          23     4         1   \n",
       "2        3304275                     15       16331    19         1   \n",
       "3        9020937                     16        6325    19         1   \n",
       "4        3082311                     17       17315    18         1   \n",
       "...          ...                    ...         ...   ...       ...   \n",
       "5999995  9958614                     19          23     4         1   \n",
       "5999996  2234489                     19        4697    19         1   \n",
       "5999997  4304572                     24          18    19         3   \n",
       "5999998  6550634                     15           6    19         3   \n",
       "5999999  6423388                     99         751    13         1   \n",
       "\n",
       "         is_privatecategory  class  is_in_yandex  is_return  weight  mailtype  \\\n",
       "0                         1    0.0             2          0    87.0       5.0   \n",
       "1                         1    0.0             1          0   107.0       5.0   \n",
       "2                         1    0.0             2          0    50.0       5.0   \n",
       "3                         1    0.0             2          0   416.0       5.0   \n",
       "4                         1    0.0             2          0   795.0       5.0   \n",
       "...                     ...    ...           ...        ...     ...       ...   \n",
       "5999995                   1    0.0             1          0    25.0       5.0   \n",
       "5999996                   1    0.0             2          0    83.0       5.0   \n",
       "5999997                   1    0.0             1          0  1700.0       5.0   \n",
       "5999998                   1    0.0             1          0   269.0       5.0   \n",
       "5999999                   1    4.0             2          0    41.0       5.0   \n",
       "\n",
       "         mailctg  mailrank  directctg  transport_pay  postmark  name_mfi  \\\n",
       "0            1.0       0.0        2.0           0.00       0.0     46654   \n",
       "1            1.0       0.0        2.0           0.00       0.0    194484   \n",
       "2            1.0       0.0        2.0           0.00       0.0     92224   \n",
       "3            1.0       0.0        2.0          35.34       0.0     79671   \n",
       "4            1.0       0.0        2.0          52.52       0.0    141303   \n",
       "...          ...       ...        ...            ...       ...       ...   \n",
       "5999995      0.0       0.0        2.0           0.00       0.0     63431   \n",
       "5999996      1.0       0.0        2.0           0.00       0.0     36730   \n",
       "5999997      1.0       0.0        2.0          94.09       0.0     37295   \n",
       "5999998      1.0       0.0        2.0           0.00       0.0       101   \n",
       "5999999      1.0       0.0        2.0           0.00       0.0     62590   \n",
       "\n",
       "         weight_mfi  price_mfi  dist_qty_oper_login_1  total_qty_oper_login_1  \\\n",
       "0              41.0      150.0                   42.0                720176.0   \n",
       "1              68.0      400.0                  914.0              48856658.0   \n",
       "2              56.0      218.0                   62.0               3246292.0   \n",
       "3              33.0      100.0                   55.0               2060928.0   \n",
       "4             716.0     1000.0                   16.0                316919.0   \n",
       "...             ...        ...                    ...                     ...   \n",
       "5999995        24.0      100.0                 1089.0              64270133.0   \n",
       "5999996       100.0     1832.0                   31.0               1767370.0   \n",
       "5999997       952.0      800.0                  186.0              60613352.0   \n",
       "5999998         0.0        0.0                  105.0              15091338.0   \n",
       "5999999        40.0      400.0                    1.0                  1541.0   \n",
       "\n",
       "         total_qty_oper_login_0  total_qty_over_index_and_type  \\\n",
       "0                       58950.0                       779126.0   \n",
       "1                    83318932.0                    132175590.0   \n",
       "2                     3233068.0                      6479360.0   \n",
       "3                      653280.0                      2714208.0   \n",
       "4                       27911.0                       344830.0   \n",
       "...                         ...                            ...   \n",
       "5999995             116432632.0                    180702765.0   \n",
       "5999996                144063.0                      1911433.0   \n",
       "5999997                 10648.0                     60624000.0   \n",
       "5999998               4972424.0                     20063762.0   \n",
       "5999999                   353.0                         1894.0   \n",
       "\n",
       "         total_qty_over_index  is_wrong_sndr_name  is_wrong_rcpn_name  \\\n",
       "0                   8290896.0                   0                   0   \n",
       "1                 136819803.0                   0                   0   \n",
       "2                  52708071.0                   0                   1   \n",
       "3                  19562334.0                   0                   0   \n",
       "4                   4719186.0                   0                   0   \n",
       "...                       ...                 ...                 ...   \n",
       "5999995           188407812.0                   0                   0   \n",
       "5999996            15582018.0                   0                   0   \n",
       "5999997            75592387.0                   0                   0   \n",
       "5999998            39988530.0                   0                   1   \n",
       "5999999               17238.0                   0                   0   \n",
       "\n",
       "         is_wrong_phone_number  is_wrong_address  label  \n",
       "0                            0                 0      0  \n",
       "1                            0                 0      0  \n",
       "2                            0                 0      0  \n",
       "3                            0                 0      0  \n",
       "4                            0                 0      0  \n",
       "...                        ...               ...    ...  \n",
       "5999995                      1                 0      0  \n",
       "5999996                      0                 0      0  \n",
       "5999997                      0                 0      0  \n",
       "5999998                      0                 0      0  \n",
       "5999999                      0                 0      0  \n",
       "\n",
       "[6000000 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train_frame.csv\",low_memory=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-7e0uZ0As9z"
   },
   "source": [
    "Обьединим список не нужных строк с списком строк типа object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PYDt4hVn_GB9"
   },
   "outputs": [],
   "source": [
    "col_obj = df.select_dtypes(include=['object']).columns.values\n",
    "col_obj = list(set(col_obj) ^ set([\"id\", \"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lcpuRWOTAoGJ",
    "outputId": "5b4db5c0-e6f8-4208-b981-aafc9c5c23c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label', 'id']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mkCL9b-8hmZ1"
   },
   "outputs": [],
   "source": [
    "X = df.drop(col_obj, axis = 1)\n",
    "y = df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NfIOX9Lbik_i"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>oper_type + oper_attr</th>\n",
       "      <th>index_oper</th>\n",
       "      <th>type</th>\n",
       "      <th>priority</th>\n",
       "      <th>is_privatecategory</th>\n",
       "      <th>class</th>\n",
       "      <th>is_in_yandex</th>\n",
       "      <th>is_return</th>\n",
       "      <th>weight</th>\n",
       "      <th>mailtype</th>\n",
       "      <th>mailctg</th>\n",
       "      <th>mailrank</th>\n",
       "      <th>directctg</th>\n",
       "      <th>transport_pay</th>\n",
       "      <th>postmark</th>\n",
       "      <th>name_mfi</th>\n",
       "      <th>weight_mfi</th>\n",
       "      <th>price_mfi</th>\n",
       "      <th>dist_qty_oper_login_1</th>\n",
       "      <th>total_qty_oper_login_1</th>\n",
       "      <th>total_qty_oper_login_0</th>\n",
       "      <th>total_qty_over_index_and_type</th>\n",
       "      <th>total_qty_over_index</th>\n",
       "      <th>is_wrong_sndr_name</th>\n",
       "      <th>is_wrong_rcpn_name</th>\n",
       "      <th>is_wrong_phone_number</th>\n",
       "      <th>is_wrong_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3877479</th>\n",
       "      <td>93</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72298</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9560324.0</td>\n",
       "      <td>2169758.0</td>\n",
       "      <td>11730082.0</td>\n",
       "      <td>11979988.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5032826</th>\n",
       "      <td>19</td>\n",
       "      <td>127</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8406</td>\n",
       "      <td>196.0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>20699228.0</td>\n",
       "      <td>49882.0</td>\n",
       "      <td>20749110.0</td>\n",
       "      <td>218661166.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5070446</th>\n",
       "      <td>17</td>\n",
       "      <td>20786</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>657.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1521.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>2367.0</td>\n",
       "      <td>24809.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4482246</th>\n",
       "      <td>17</td>\n",
       "      <td>16339</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104192</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>456104.0</td>\n",
       "      <td>14495806.0</td>\n",
       "      <td>14951910.0</td>\n",
       "      <td>15022023.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398411</th>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119179</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>60613352.0</td>\n",
       "      <td>10648.0</td>\n",
       "      <td>60624000.0</td>\n",
       "      <td>75592387.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333373</th>\n",
       "      <td>16</td>\n",
       "      <td>15670</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60585</td>\n",
       "      <td>300.0</td>\n",
       "      <td>9300.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13933.0</td>\n",
       "      <td>5720.0</td>\n",
       "      <td>19653.0</td>\n",
       "      <td>274188.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3666771</th>\n",
       "      <td>58</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46934</td>\n",
       "      <td>19.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>914.0</td>\n",
       "      <td>48856658.0</td>\n",
       "      <td>83318932.0</td>\n",
       "      <td>132175590.0</td>\n",
       "      <td>136819803.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5484193</th>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>38.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2611</td>\n",
       "      <td>86.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>64270133.0</td>\n",
       "      <td>116432632.0</td>\n",
       "      <td>180702765.0</td>\n",
       "      <td>188407812.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196076</th>\n",
       "      <td>17</td>\n",
       "      <td>9746</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1113748.0</td>\n",
       "      <td>351845.0</td>\n",
       "      <td>1465593.0</td>\n",
       "      <td>9888343.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135796</th>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>210481</td>\n",
       "      <td>191.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1089.0</td>\n",
       "      <td>64270133.0</td>\n",
       "      <td>116432632.0</td>\n",
       "      <td>180702765.0</td>\n",
       "      <td>188407812.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5940000 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         oper_type + oper_attr  index_oper  type  priority  \\\n",
       "3877479                     93          16    15         1   \n",
       "5032826                     19         127    19         3   \n",
       "5070446                     17       20786    13         2   \n",
       "4482246                     17       16339    18         1   \n",
       "1398411                     17          18    19         3   \n",
       "...                        ...         ...   ...       ...   \n",
       "333373                      16       15670     3         1   \n",
       "3666771                     58          23     4         1   \n",
       "5484193                      9          23     4         1   \n",
       "196076                      17        9746    18         1   \n",
       "2135796                     16          23     4         1   \n",
       "\n",
       "         is_privatecategory  class  is_in_yandex  is_return  weight  mailtype  \\\n",
       "3877479                   1    0.0             1          0   435.0       5.0   \n",
       "5032826                   1    0.0             1          0  1307.0       5.0   \n",
       "5070446                   1    3.0             2          0   657.0       5.0   \n",
       "4482246                   1    0.0             1          0    13.0       5.0   \n",
       "1398411                   1    0.0             1          0    10.0       5.0   \n",
       "...                     ...    ...           ...        ...     ...       ...   \n",
       "333373                    1    3.0             2          0   434.0       5.0   \n",
       "3666771                   1    0.0             1          0    41.0       5.0   \n",
       "5484193                   1    0.0             1          0   475.0       5.0   \n",
       "196076                    1    0.0             2          0   302.0       5.0   \n",
       "2135796                   1    0.0             1          0   212.0       5.0   \n",
       "\n",
       "         mailctg  mailrank  directctg  transport_pay  postmark  name_mfi  \\\n",
       "3877479      1.0       0.0        2.0           0.00       0.0     72298   \n",
       "5032826      1.0       0.0        2.0           0.00       0.0      8406   \n",
       "5070446      1.0       0.0        2.0           0.00       0.0       101   \n",
       "4482246      0.0       0.0        2.0           0.00       0.0    104192   \n",
       "1398411      0.0       0.0        2.0           0.00       0.0    119179   \n",
       "...          ...       ...        ...            ...       ...       ...   \n",
       "333373       1.0       0.0        2.0           0.00       0.0     60585   \n",
       "3666771      1.0       0.0        2.0           0.00       0.0     46934   \n",
       "5484193      1.0       0.0        2.0          38.11       0.0      2611   \n",
       "196076       1.0       0.0        2.0          33.01       0.0       101   \n",
       "2135796      1.0       0.0        2.0          25.90       0.0    210481   \n",
       "\n",
       "         weight_mfi  price_mfi  dist_qty_oper_login_1  total_qty_oper_login_1  \\\n",
       "3877479       400.0     1800.0                   40.0               9560324.0   \n",
       "5032826       196.0     4716.0                  137.0              20699228.0   \n",
       "5070446         0.0        0.0                    2.0                  1521.0   \n",
       "4482246        20.0      100.0                   16.0                456104.0   \n",
       "1398411        10.0      100.0                  186.0              60613352.0   \n",
       "...             ...        ...                    ...                     ...   \n",
       "333373        300.0     9300.0                   17.0                 13933.0   \n",
       "3666771        19.0       50.0                  914.0              48856658.0   \n",
       "5484193        86.0      133.0                 1089.0              64270133.0   \n",
       "196076          0.0        0.0                   20.0               1113748.0   \n",
       "2135796       191.0      120.0                 1089.0              64270133.0   \n",
       "\n",
       "         total_qty_oper_login_0  total_qty_over_index_and_type  \\\n",
       "3877479               2169758.0                     11730082.0   \n",
       "5032826                 49882.0                     20749110.0   \n",
       "5070446                   846.0                         2367.0   \n",
       "4482246              14495806.0                     14951910.0   \n",
       "1398411                 10648.0                     60624000.0   \n",
       "...                         ...                            ...   \n",
       "333373                   5720.0                        19653.0   \n",
       "3666771              83318932.0                    132175590.0   \n",
       "5484193             116432632.0                    180702765.0   \n",
       "196076                 351845.0                      1465593.0   \n",
       "2135796             116432632.0                    180702765.0   \n",
       "\n",
       "         total_qty_over_index  is_wrong_sndr_name  is_wrong_rcpn_name  \\\n",
       "3877479            11979988.0                   0                   0   \n",
       "5032826           218661166.0                   0                   0   \n",
       "5070446               24809.0                   0                   1   \n",
       "4482246            15022023.0                   0                   0   \n",
       "1398411            75592387.0                   0                   1   \n",
       "...                       ...                 ...                 ...   \n",
       "333373               274188.0                   0                   0   \n",
       "3666771           136819803.0                   0                   0   \n",
       "5484193           188407812.0                   0                   0   \n",
       "196076              9888343.0                   0                   1   \n",
       "2135796           188407812.0                   0                   1   \n",
       "\n",
       "         is_wrong_phone_number  is_wrong_address  \n",
       "3877479                      0                 0  \n",
       "5032826                      0                 0  \n",
       "5070446                      0                 0  \n",
       "4482246                      0                 0  \n",
       "1398411                      1                 0  \n",
       "...                        ...               ...  \n",
       "333373                       0                 0  \n",
       "3666771                      0                 0  \n",
       "5484193                      0                 0  \n",
       "196076                       0                 0  \n",
       "2135796                      0                 0  \n",
       "\n",
       "[5940000 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42,n_jobs=10)\n",
    "\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11541490, 27)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60NotS9ehbO5"
   },
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "# logistic = OneVsRestClassifier(RandomForestClassifier(max_depth=22,n_jobs=-1))\n",
    "#logistic=GaussianNB()\n",
    "#pipe = Pipeline([('normalizer', scaler), ('classifier', logistic)])\n",
    "#pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf1=HistGradientBoostingClassifier(learning_rate=0.1,max_depth=8, min_samples_leaf=100)\n",
    "clf2=RandomForestClassifier(max_depth=15,n_jobs=9)\n",
    "clf3=GaussianNB()\n",
    "eclf1 = VotingClassifier([('gb', clf1),('rf', clf2),('gnb', clf3)], voting='soft',weights=[1,1.1,1.2])\n",
    "pipe = Pipeline([('normalizer', scaler), ('classifier', eclf1)])\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictions = pipe.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pool_train = cb.Pool(X, y)\n",
    "params = {                  # 'task_type':'GPU',\n",
    "                            'iterations':1200,\n",
    "                            'depth':8,\n",
    "                            'random_state':2,\n",
    "                            'learning_rate':0.01,\n",
    "                            'eval_metric':'Recall',\n",
    "                            'loss_function':'MultiCrossEntropy'}\n",
    "clf_with_aux = cb.CatBoostClassifier(**params)\n",
    "clf_with_aux.fit(pool_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predcat = clf_with_aux.predict_proba(X_test)\n",
    "voting = pipe.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "y_pred = ((voting + predcat) / 2).argmax(axis=1)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "parametrs = {\n",
    "              'max_depth': range (1,35),\n",
    "            }\n",
    "grid = GridSearchCV(RandomForestClassifier(), parametrs, scoring='roc_auc', cv=2,n_jobs=9) \n",
    "grid.fit(X_test, y_test) \n",
    "grid.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pkl_filename = \"model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(pipe, file)\n",
    "\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nb_classifier = GaussianNB()\n",
    "\n",
    "params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "gs_NB = GridSearchCV(estimator=nb_classifier, \n",
    "                 param_grid=params_NB, \n",
    "                 cv=2,   # use any cross validation technique \n",
    "                 verbose=1, \n",
    "                 scoring='roc_auc') \n",
    "gs_NB.fit(X_train, y_train)\n",
    "\n",
    "gs_NB.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gb_grid_params = {'learning_rate': [0.1, 0.05, 0.02, 0.01],\n",
    "              'max_depth': [4, 6, 8],\n",
    "              'min_samples_leaf': [20, 50,100,150],\n",
    "              #'max_features': [1.0, 0.3, 0.1] \n",
    "              }\n",
    "print(gb_grid_params)\n",
    "\n",
    "gb_gs = HistGradientBoostingClassifier()\n",
    "\n",
    "clf = GridSearchCV(gb_gs,\n",
    "                               gb_grid_params,\n",
    "                               cv=2,\n",
    "                               scoring='roc_auc',\n",
    "                               verbose = 3, \n",
    "                               n_jobs=2);\n",
    "clf.fit(X_train, y_train);\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейронка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-10 19:54:32.502323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-10 19:54:32.503586: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-10 19:54:32.503780: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-11-10 19:54:32.503938: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-11-10 19:54:32.504098: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-11-10 19:54:32.504255: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-11-10 19:54:32.504409: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-11-10 19:54:32.504558: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-11-10 19:54:32.504702: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-11-10 19:54:32.504729: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-11-10 19:54:32.505918: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "22542/22542 [==============================] - 58s 3ms/step - loss: 0.1742 - recall: 0.9724 - val_loss: 0.4406 - val_recall: 0.8099\n",
      "Epoch 2/5\n",
      "22542/22542 [==============================] - 57s 3ms/step - loss: 0.1175 - recall: 0.9782 - val_loss: 1.1643 - val_recall: 0.7455\n",
      "Epoch 3/5\n",
      "22542/22542 [==============================] - 57s 3ms/step - loss: 0.0976 - recall: 0.9869 - val_loss: 2.1289 - val_recall: 0.7536\n",
      "Epoch 4/5\n",
      "22542/22542 [==============================] - 56s 2ms/step - loss: 0.0900 - recall: 0.9935 - val_loss: 2.6846 - val_recall: 0.7438\n",
      "Epoch 5/5\n",
      "22542/22542 [==============================] - 56s 2ms/step - loss: 0.0862 - recall: 0.9940 - val_loss: 2.5775 - val_recall: 0.7194\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "import tensorflow as tf \n",
    "def build_model1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(270,activation='sigmoid',input_shape=(27,)))\n",
    "    model.add(layers.Dense(9,activation='relu'))\n",
    "    model.add(layers.Dense(1,activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop',# Вы также можете указать параметры для оптимизатора через optimizer = optimizer.RMSprop (lr = 0.001)\n",
    "                  loss='binary_crossentropy', # Эквивалент потерь = loss.binary_crossentropy\n",
    "                  metrics=[tf.keras.metrics.Recall()]) # Эквивалентно метрике = [metircs.binary_accuracy]\n",
    "    return model\n",
    "model1 = build_model1()\n",
    "\n",
    "\n",
    "history = model1.fit(X_train, y_train,\n",
    "                    epochs=5, # Итерировать 20 раз по полному набору данных\n",
    "                    batch_size=512, # Размер каждой партии 512\n",
    "                    validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 2s 835us/step\n",
      "нейронка               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.77      0.87     58275\n",
      "           1       0.09      0.72      0.15      1725\n",
      "\n",
      "    accuracy                           0.77     60000\n",
      "   macro avg       0.54      0.75      0.51     60000\n",
      "weighted avg       0.96      0.77      0.85     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model1.predict(X_test)\n",
    "pred=[]\n",
    "for i in predictions:\n",
    "    pred.append(round(float(i)))\n",
    "print('нейронка',classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейронка 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22542/22542 [==============================] - 86s 4ms/step - loss: 0.1167 - recall_3: 0.9861 - val_loss: 0.2482 - val_recall_3: 0.7501\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "import tensorflow as tf \n",
    "def build_model2():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(270,activation='sigmoid',input_shape=(27,)))\n",
    "    model.add(layers.Dense(90,activation='relu'))\n",
    "    model.add(layers.Dense(30,activation='relu'))\n",
    "    model.add(layers.Dense(1,activation='sigmoid'))\n",
    "    model.compile(optimizer='adam',# Вы также можете указать параметры для оптимизатора через optimizer = optimizer.RMSprop (lr = 0.001)\n",
    "                  loss='binary_crossentropy', # Эквивалент потерь = loss.binary_crossentropy\n",
    "                  metrics=[tf.keras.metrics.Recall()]) # Эквивалентно метрике = [metircs.binary_accuracy]\n",
    "    return model\n",
    "model2 = build_model2()\n",
    "\n",
    "\n",
    "history = model2.fit(X_train, y_train,\n",
    "                    epochs=1, # Итерировать 20 раз по полному набору данных\n",
    "                    batch_size=512, # Размер каждой партии 512\n",
    "                    validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 2s 988us/step\n",
      "нейронка               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95     58275\n",
      "           1       0.21      0.75      0.33      1725\n",
      "\n",
      "    accuracy                           0.91     60000\n",
      "   macro avg       0.60      0.83      0.64     60000\n",
      "weighted avg       0.97      0.91      0.93     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model2.predict(X_test)\n",
    "pred=[]\n",
    "for i in predictions:\n",
    "    pred.append(round(float(i)))\n",
    "print('нейронка',classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 2s 802us/step\n",
      "1875/1875 [==============================] - 2s 894us/step\n",
      "нейронка               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93     58275\n",
      "           1       0.16      0.73      0.26      1725\n",
      "\n",
      "    accuracy                           0.88     60000\n",
      "   macro avg       0.57      0.81      0.59     60000\n",
      "weighted avg       0.97      0.88      0.91     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_nero = pd.DataFrame() \n",
    "df_nero['1']= model1.predict(X_test).flatten().tolist ()\n",
    "\n",
    "df_nero['2']= model2.predict(X_test).flatten().tolist ()\n",
    "\n",
    "df_nero['pre']=(df_nero['1']+df_nero['2'])/2\n",
    "\n",
    "pred=[]\n",
    "for i in  df_nero['pre']:\n",
    "    pred.append(round(float(i)))\n",
    "\n",
    "print('нейронка',classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrF2LeJIBNYN"
   },
   "source": [
    "## Оценка точности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Ph7vcoxBNYO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "wfAZwwLXBNYO"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "score = recall_score(y_test, pred, average = \"macro\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sX6yHTGUBNYO",
    "outputId": "ab784c04-2e8c-4595-a968-d22f9923b4bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall 0.8077458825284912\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93     58275\n",
      "           1       0.16      0.73      0.26      1725\n",
      "\n",
      "    accuracy                           0.88     60000\n",
      "   macro avg       0.57      0.81      0.59     60000\n",
      "weighted avg       0.97      0.88      0.91     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предсказание "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data=pd.read_csv('test_dataset_test.csv',low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"priority\"] = pd.Categorical(df[\"priority\"])\n",
    "df[\"priority\"].astype('category').cat.codes\n",
    "df[\"priority\"] = df[\"priority\"].cat.codes\n",
    "df[\"is_in_yandex\"] = pd.Categorical(df[\"is_in_yandex\"])\n",
    "df[\"is_in_yandex\"].astype('category').cat.codes\n",
    "df[\"is_in_yandex\"] = df[\"is_in_yandex\"].cat.codes\n",
    "df[\"is_return\"] = pd.Categorical(df[\"is_return\"])\n",
    "df[\"is_return\"].astype('category').cat.codes\n",
    "df[\"is_return\"] = df[\"is_return\"].cat.codes\n",
    "df[\"oper_type + oper_attr\"] = pd.Categorical(df[\"oper_type + oper_attr\"])\n",
    "df[\"oper_type + oper_attr\"].astype('category').cat.codes\n",
    "df[\"oper_type + oper_attr\"] = df[\"oper_type + oper_attr\"].cat.codes\n",
    "df[\"index_oper\"] = pd.Categorical(df[\"index_oper\"])\n",
    "df[\"index_oper\"].astype('category').cat.codes\n",
    "df[\"index_oper\"] = df[\"index_oper\"].cat.codes\n",
    "df[\"type\"] = pd.Categorical(df[\"type\"])\n",
    "df[\"type\"].astype('category').cat.codes\n",
    "df[\"type\"] = df[\"type\"].cat.codes\n",
    "df[\"is_privatecategory\"] = pd.Categorical(df[\"is_privatecategory\"])\n",
    "df[\"is_privatecategory\"].astype('category').cat.codes\n",
    "df[\"is_privatecategory\"] = df[\"is_privatecategory\"].cat.codes\n",
    "df[\"name_mfi\"] = pd.Categorical(df[\"name_mfi\"])\n",
    "df[\"name_mfi\"].astype('category').cat.codes\n",
    "df[\"name_mfi\"] = df[\"name_mfi\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[43mpipe\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipe' is not defined"
     ]
    }
   ],
   "source": [
    "pred_data['label']=pipe.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data[['id','label']].to_csv('bestmodel.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейро "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gennalll/.local/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21912/125000 [====>.........................] - ETA: 1:36"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m df\u001b[38;5;241m=\u001b[39mscaler\u001b[38;5;241m.\u001b[39mtransform(df)\n\u001b[0;32m----> 2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m pred\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m predictions:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:2265\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2260\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m   2261\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m batch_output: [batch_output],\n\u001b[1;32m   2262\u001b[0m         batch_outputs,\n\u001b[1;32m   2263\u001b[0m     )\n\u001b[1;32m   2264\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2265\u001b[0m     \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure_up_to\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2267\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_output\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2268\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_output\u001b[49m\n\u001b[1;32m   2269\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2270\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2272\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2273\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m   2274\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_end(\n\u001b[1;32m   2275\u001b[0m     end_step, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch_outputs}\n\u001b[1;32m   2276\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1428\u001b[0m, in \u001b[0;36mmap_structure_up_to\u001b[0;34m(shallow_tree, func, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1354\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__internal__.nest.map_structure_up_to\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m   1355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure_up_to\u001b[39m(shallow_tree, func, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1356\u001b[0m   \u001b[38;5;124;03m\"\"\"Applies a function or op to a number of partially flattened inputs.\u001b[39;00m\n\u001b[1;32m   1357\u001b[0m \n\u001b[1;32m   1358\u001b[0m \u001b[38;5;124;03m  The `inputs` are flattened up to `shallow_tree` before being mapped.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;124;03m    `shallow_tree`.\u001b[39;00m\n\u001b[1;32m   1427\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1428\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_structure_with_tuple_paths_up_to\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1429\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshallow_tree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1430\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Discards the path arg.\u001b[39;49;00m\n\u001b[1;32m   1431\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1432\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1511\u001b[0m, in \u001b[0;36mmap_structure_with_tuple_paths_up_to\u001b[0;34m(shallow_tree, func, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1508\u001b[0m is_nested_fn \u001b[38;5;241m=\u001b[39m _is_nested_or_composite \u001b[38;5;28;01mif\u001b[39;00m expand_composites \u001b[38;5;28;01melse\u001b[39;00m _is_nested\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_tree \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[0;32m-> 1511\u001b[0m   \u001b[43massert_shallow_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshallow_tree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1513\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_tree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1514\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcheck_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[43m      \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_composites\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;66;03m# Flatten each input separately, apply the function to corresponding items,\u001b[39;00m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;66;03m# then repack based on the structure of the first input.\u001b[39;00m\n\u001b[1;32m   1519\u001b[0m flat_value_gen \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1520\u001b[0m     flatten_up_to(  \u001b[38;5;66;03m# pylint: disable=g-complex-comprehension\u001b[39;00m\n\u001b[1;32m   1521\u001b[0m         shallow_tree,\n\u001b[1;32m   1522\u001b[0m         input_tree,\n\u001b[1;32m   1523\u001b[0m         check_types,\n\u001b[1;32m   1524\u001b[0m         expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites) \u001b[38;5;28;01mfor\u001b[39;00m input_tree \u001b[38;5;129;01min\u001b[39;00m inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py:1075\u001b[0m, in \u001b[0;36massert_shallow_structure\u001b[0;34m(shallow_tree, input_tree, check_types, expand_composites)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massert_shallow_structure\u001b[39m(shallow_tree,\n\u001b[1;32m   1033\u001b[0m                              input_tree,\n\u001b[1;32m   1034\u001b[0m                              check_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1035\u001b[0m                              expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1036\u001b[0m   \u001b[38;5;124;03m\"\"\"Asserts that `shallow_tree` is a shallow structure of `input_tree`.\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \n\u001b[1;32m   1038\u001b[0m \u001b[38;5;124;03m  That is, this function tests if the `input_tree` structure can be created from\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;124;03m      `input_tree`.\u001b[39;00m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1075\u001b[0m   is_nested_fn \u001b[38;5;241m=\u001b[39m _is_nested_or_composite \u001b[38;5;28;01mif\u001b[39;00m expand_composites \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_is_nested\u001b[49m\n\u001b[1;32m   1076\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m is_nested_fn(shallow_tree):\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_nested_fn(input_tree):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df=scaler.transform(df)\n",
    "predictions = model2.predict(df)\n",
    "pred=[]\n",
    "for i in predictions:\n",
    "    pred.append(round(float(i)))\n",
    "pred_data['label']=pred\n",
    "pred_data[['id','label']].to_csv('bestmodelnero.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейро 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125000/125000 [==============================] - 104s 830us/step\n",
      "125000/125000 [==============================] - 116s 928us/step\n"
     ]
    }
   ],
   "source": [
    "df_nero = pd.DataFrame() \n",
    "df_nero['1']= model1.predict(df).flatten().tolist ()\n",
    "\n",
    "df_nero['2']= model2.predict(df).flatten().tolist ()\n",
    "\n",
    "df_nero['pre']=(df_nero['1']+df_nero['2'])/2\n",
    "\n",
    "pred=[]\n",
    "for i in  df_nero['pre']:\n",
    "    pred.append(round(float(i)))\n",
    "pred_data['label']=pred\n",
    "pred_data[['id','label']].to_csv('bestmodelnero2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
