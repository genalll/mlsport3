{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnE1_J-4dhSR"
   },
   "source": [
    "## Загрузим нужные библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uaKzqUxsdjDa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /home/gennalll/.local/lib/python3.8/site-packages (1.1.1)\n",
      "Requirement already satisfied: graphviz in /home/gennalll/.local/lib/python3.8/site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (from catboost) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/gennalll/.local/lib/python3.8/site-packages (from catboost) (1.23.3)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /home/gennalll/.local/lib/python3.8/site-packages (from catboost) (1.4.1)\n",
      "Requirement already satisfied: scipy in /home/gennalll/.local/lib/python3.8/site-packages (from catboost) (1.8.0)\n",
      "Requirement already satisfied: plotly in /home/gennalll/.local/lib/python3.8/site-packages (from catboost) (5.10.0)\n",
      "Requirement already satisfied: six in /home/gennalll/.local/lib/python3.8/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/gennalll/.local/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gennalll/.local/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2021.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/gennalll/.local/lib/python3.8/site-packages (from plotly->catboost) (8.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 14:41:59.680630: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-09 14:41:59.806551: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-09 14:41:59.806570: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-09 14:41:59.841036: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-09 14:42:00.462789: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-09 14:42:00.462858: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-09 14:42:00.462867: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import uniform\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import svm\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import catboost as cb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_frame.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-7e0uZ0As9z"
   },
   "source": [
    "Обьединим список не нужных строк с списком строк типа object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PYDt4hVn_GB9"
   },
   "outputs": [],
   "source": [
    "col_obj = df.select_dtypes(include=['object']).columns.values\n",
    "col_obj = list(set(col_obj) ^ set([\"id\", \"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lcpuRWOTAoGJ",
    "outputId": "5b4db5c0-e6f8-4208-b981-aafc9c5c23c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'label']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "mkCL9b-8hmZ1"
   },
   "outputs": [],
   "source": [
    "X = df.drop(col_obj, axis = 1)\n",
    "y = df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NfIOX9Lbik_i"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf=PolynomialFeatures() \n",
    "X_train=pf.fit_transform(X_train)\n",
    "X_test=pf.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60NotS9ehbO5"
   },
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "#scaler.fit(X)\n",
    "# logistic = OneVsRestClassifier(RandomForestClassifier(max_depth=22,n_jobs=-1))\n",
    "#logistic=GaussianNB()\n",
    "#pipe = Pipeline([('normalizer', scaler), ('classifier', logistic)])\n",
    "#pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1=ComplementNB()\n",
    "clf3=GaussianNB()\n",
    "eclf1 = VotingClassifier([('cnb', clf1),('gb', clf3)], voting='soft',weights=[1,1,1])\n",
    "pipe = Pipeline([('normalizer', scaler), ('classifier', eclf1)])\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pool_train = cb.Pool(X, y)\n",
    "params = {                  # 'task_type':'GPU',\n",
    "                            'iterations':1200,\n",
    "                            'depth':8,\n",
    "                            'random_state':2,\n",
    "                            'learning_rate':0.01,\n",
    "                            'eval_metric':'HammingLoss',\n",
    "                            'loss_function':'MultiCrossEntropy'}\n",
    "clf_with_aux = cb.CatBoostClassifier(**params)\n",
    "clf_with_aux.fit(pool_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predcat = clf_with_aux.predict_proba(X_test)\n",
    "voting = pipe.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "y_pred = ((voting + predcat) / 2).argmax(axis=1)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "parametrs = {\n",
    "              'max_depth': range (1,25),\n",
    "            }\n",
    "grid = GridSearchCV(DecisionTreeClassifier(), parametrs, scoring='roc_auc', cv=2,n_jobs=-1) \n",
    "grid.fit(X_test, y_test) \n",
    "grid.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pkl_filename = \"model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(pipe, file)\n",
    "\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nb_classifier = GaussianNB()\n",
    "\n",
    "params_NB = {'var_smoothing': np.logspace(0,-9, num=10)}\n",
    "gs_NB = GridSearchCV(estimator=nb_classifier, \n",
    "                 param_grid=params_NB, \n",
    "                 cv=2,   # use any cross validation technique \n",
    "                 verbose=1, \n",
    "                 scoring='recall') \n",
    "gs_NB.fit(X_train, y_train)\n",
    "\n",
    "gs_NB.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейронка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "import tensorflow as tf \n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(27,activation='sigmoid',input_shape=(27,)))\n",
    "    model.add(layers.Dense(1000,activation='sigmoid'))\n",
    "    model.add(layers.Dense(1,activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop',# Вы также можете указать параметры для оптимизатора через optimizer = optimizer.RMSprop (lr = 0.001)\n",
    "                  loss='binary_crossentropy', # Эквивалент потерь = loss.binary_crossentropy\n",
    "                  metrics=[tf.keras.metrics.Recall()]) # Эквивалентно метрике = [metircs.binary_accuracy]\n",
    "    return model\n",
    "model = build_model()\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=2, # Итерировать 20 раз по полному набору данных\n",
    "                    batch_size=512, # Размер каждой партии 512\n",
    "                    validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictions = model.predict(X_test)\n",
    "pred=[]\n",
    "for i in predictions:\n",
    "    pred.append(np.argmax(i+1))\n",
    "print('нейронка',classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrF2LeJIBNYN"
   },
   "source": [
    "## Оценка точности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Ph7vcoxBNYO"
   },
   "outputs": [],
   "source": [
    "pred =pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfAZwwLXBNYO"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "score = recall_score(y_test, pred, average = \"macro\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sX6yHTGUBNYO",
    "outputId": "ab784c04-2e8c-4595-a968-d22f9923b4bd"
   },
   "outputs": [],
   "source": [
    "print(\"Recall\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test,  pipe.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Требуемая величина', 0.1*score+0.9*roc_auc_score(y_test,  pipe.predict_proba(X_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предсказание "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data=pd.read_csv('test_dataset_test.csv',low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"priority\"] = pd.Categorical(df[\"priority\"])\n",
    "df[\"priority\"].astype('category').cat.codes\n",
    "df[\"priority\"] = df[\"priority\"].cat.codes\n",
    "df[\"is_in_yandex\"] = pd.Categorical(df[\"is_in_yandex\"])\n",
    "df[\"is_in_yandex\"].astype('category').cat.codes\n",
    "df[\"is_in_yandex\"] = df[\"is_in_yandex\"].cat.codes\n",
    "df[\"is_return\"] = pd.Categorical(df[\"is_return\"])\n",
    "df[\"is_return\"].astype('category').cat.codes\n",
    "df[\"is_return\"] = df[\"is_return\"].cat.codes\n",
    "df[\"oper_type + oper_attr\"] = pd.Categorical(df[\"oper_type + oper_attr\"])\n",
    "df[\"oper_type + oper_attr\"].astype('category').cat.codes\n",
    "df[\"oper_type + oper_attr\"] = df[\"oper_type + oper_attr\"].cat.codes\n",
    "df[\"index_oper\"] = pd.Categorical(df[\"index_oper\"])\n",
    "df[\"index_oper\"].astype('category').cat.codes\n",
    "df[\"index_oper\"] = df[\"index_oper\"].cat.codes\n",
    "df[\"type\"] = pd.Categorical(df[\"type\"])\n",
    "df[\"type\"].astype('category').cat.codes\n",
    "df[\"type\"] = df[\"type\"].cat.codes\n",
    "df[\"is_privatecategory\"] = pd.Categorical(df[\"is_privatecategory\"])\n",
    "df[\"is_privatecategory\"].astype('category').cat.codes\n",
    "df[\"is_privatecategory\"] = df[\"is_privatecategory\"].cat.codes\n",
    "df[\"name_mfi\"] = pd.Categorical(df[\"name_mfi\"])\n",
    "df[\"name_mfi\"].astype('category').cat.codes\n",
    "df[\"name_mfi\"] = df[\"name_mfi\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data['label']=pipe.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data[['id','label']].to_csv('bestmodel.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
