{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fnE1_J-4dhSR"
   },
   "source": [
    "## Загрузим нужные библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uaKzqUxsdjDa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /home/gennalll/.local/lib/python3.8/site-packages (1.1.1)\n",
      "Requirement already satisfied: graphviz in /home/gennalll/.local/lib/python3.8/site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (from catboost) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /home/gennalll/.local/lib/python3.8/site-packages (from catboost) (1.23.3)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /home/gennalll/.local/lib/python3.8/site-packages (from catboost) (1.4.1)\n",
      "Requirement already satisfied: scipy in /home/gennalll/.local/lib/python3.8/site-packages (from catboost) (1.8.0)\n",
      "Requirement already satisfied: plotly in /home/gennalll/.local/lib/python3.8/site-packages (from catboost) (5.10.0)\n",
      "Requirement already satisfied: six in /home/gennalll/.local/lib/python3.8/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/gennalll/.local/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gennalll/.local/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2021.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/gennalll/.local/lib/python3.8/site-packages (from plotly->catboost) (8.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 10:23:42.391016: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-11 10:23:42.530830: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-11 10:23:42.530858: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-11 10:23:42.567042: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-11 10:23:43.181456: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-11 10:23:43.181534: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-11 10:23:43.181542: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import uniform\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import svm\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import catboost as cb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>oper_type + oper_attr</th>\n",
       "      <th>index_oper</th>\n",
       "      <th>type</th>\n",
       "      <th>priority</th>\n",
       "      <th>is_privatecategory</th>\n",
       "      <th>class</th>\n",
       "      <th>is_in_yandex</th>\n",
       "      <th>is_return</th>\n",
       "      <th>weight</th>\n",
       "      <th>...</th>\n",
       "      <th>total_qty_oper_login_0</th>\n",
       "      <th>total_qty_over_index_and_type</th>\n",
       "      <th>total_qty_over_index</th>\n",
       "      <th>is_wrong_sndr_name</th>\n",
       "      <th>is_wrong_rcpn_name</th>\n",
       "      <th>is_wrong_phone_number</th>\n",
       "      <th>is_wrong_address</th>\n",
       "      <th>label</th>\n",
       "      <th>is_wrong</th>\n",
       "      <th>total_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6818780</td>\n",
       "      <td>26</td>\n",
       "      <td>17235</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58950.0</td>\n",
       "      <td>779126.0</td>\n",
       "      <td>8290896.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.093974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9907176</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>83318932.0</td>\n",
       "      <td>132175590.0</td>\n",
       "      <td>136819803.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.966056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3304275</td>\n",
       "      <td>15</td>\n",
       "      <td>16331</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3233068.0</td>\n",
       "      <td>6479360.0</td>\n",
       "      <td>52708071.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.122929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9020937</td>\n",
       "      <td>16</td>\n",
       "      <td>6325</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>653280.0</td>\n",
       "      <td>2714208.0</td>\n",
       "      <td>19562334.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3082311</td>\n",
       "      <td>17</td>\n",
       "      <td>17315</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27911.0</td>\n",
       "      <td>344830.0</td>\n",
       "      <td>4719186.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.073070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999995</th>\n",
       "      <td>9958614</td>\n",
       "      <td>19</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>116432632.0</td>\n",
       "      <td>180702765.0</td>\n",
       "      <td>188407812.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.959104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999996</th>\n",
       "      <td>2234489</td>\n",
       "      <td>19</td>\n",
       "      <td>4697</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>144063.0</td>\n",
       "      <td>1911433.0</td>\n",
       "      <td>15582018.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.122669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999997</th>\n",
       "      <td>4304572</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10648.0</td>\n",
       "      <td>60624000.0</td>\n",
       "      <td>75592387.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.801986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999998</th>\n",
       "      <td>6550634</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4972424.0</td>\n",
       "      <td>20063762.0</td>\n",
       "      <td>39988530.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.501738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999999</th>\n",
       "      <td>6423388</td>\n",
       "      <td>99</td>\n",
       "      <td>751</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>353.0</td>\n",
       "      <td>1894.0</td>\n",
       "      <td>17238.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.109874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000000 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  oper_type + oper_attr  index_oper  type  priority  \\\n",
       "0        6818780                     26       17235    18         1   \n",
       "1        9907176                     20          23     4         1   \n",
       "2        3304275                     15       16331    19         1   \n",
       "3        9020937                     16        6325    19         1   \n",
       "4        3082311                     17       17315    18         1   \n",
       "...          ...                    ...         ...   ...       ...   \n",
       "5999995  9958614                     19          23     4         1   \n",
       "5999996  2234489                     19        4697    19         1   \n",
       "5999997  4304572                     24          18    19         3   \n",
       "5999998  6550634                     15           6    19         3   \n",
       "5999999  6423388                     99         751    13         1   \n",
       "\n",
       "         is_privatecategory  class  is_in_yandex  is_return  weight  ...  \\\n",
       "0                         1    0.0             2          0     0.0  ...   \n",
       "1                         1    0.0             1          0     0.0  ...   \n",
       "2                         1    0.0             2          0     0.0  ...   \n",
       "3                         1    0.0             2          0     0.0  ...   \n",
       "4                         1    0.0             2          0     1.0  ...   \n",
       "...                     ...    ...           ...        ...     ...  ...   \n",
       "5999995                   1    0.0             1          0     0.0  ...   \n",
       "5999996                   1    0.0             2          0     0.0  ...   \n",
       "5999997                   1    0.0             1          0     2.0  ...   \n",
       "5999998                   1    0.0             1          0     0.0  ...   \n",
       "5999999                   1    4.0             2          0     0.0  ...   \n",
       "\n",
       "         total_qty_oper_login_0  total_qty_over_index_and_type  \\\n",
       "0                       58950.0                       779126.0   \n",
       "1                    83318932.0                    132175590.0   \n",
       "2                     3233068.0                      6479360.0   \n",
       "3                      653280.0                      2714208.0   \n",
       "4                       27911.0                       344830.0   \n",
       "...                         ...                            ...   \n",
       "5999995             116432632.0                    180702765.0   \n",
       "5999996                144063.0                      1911433.0   \n",
       "5999997                 10648.0                     60624000.0   \n",
       "5999998               4972424.0                     20063762.0   \n",
       "5999999                   353.0                         1894.0   \n",
       "\n",
       "         total_qty_over_index  is_wrong_sndr_name  is_wrong_rcpn_name  \\\n",
       "0                   8290896.0                   0                   0   \n",
       "1                 136819803.0                   0                   0   \n",
       "2                  52708071.0                   0                   1   \n",
       "3                  19562334.0                   0                   0   \n",
       "4                   4719186.0                   0                   0   \n",
       "...                       ...                 ...                 ...   \n",
       "5999995           188407812.0                   0                   0   \n",
       "5999996            15582018.0                   0                   0   \n",
       "5999997            75592387.0                   0                   0   \n",
       "5999998            39988530.0                   0                   1   \n",
       "5999999               17238.0                   0                   0   \n",
       "\n",
       "         is_wrong_phone_number  is_wrong_address  label  is_wrong  total_mean  \n",
       "0                            0                 0      0         0    0.093974  \n",
       "1                            0                 0      0         0    0.966056  \n",
       "2                            0                 0      0         1    0.122929  \n",
       "3                            0                 0      0         0    0.138747  \n",
       "4                            0                 0      0         0    0.073070  \n",
       "...                        ...               ...    ...       ...         ...  \n",
       "5999995                      1                 0      0         1    0.959104  \n",
       "5999996                      0                 0      0         0    0.122669  \n",
       "5999997                      0                 0      0         0    0.801986  \n",
       "5999998                      0                 0      0         1    0.501738  \n",
       "5999999                      0                 0      0         0    0.109874  \n",
       "\n",
       "[6000000 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train_frame.csv\",low_memory=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5829020\n",
       "1     170980\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-7e0uZ0As9z"
   },
   "source": [
    "Обьединим список не нужных строк с списком строк типа object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PYDt4hVn_GB9"
   },
   "outputs": [],
   "source": [
    "col_obj = df.select_dtypes(include=['object']).columns.values\n",
    "col_obj = list(set(col_obj) ^ set([\"id\", \"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lcpuRWOTAoGJ",
    "outputId": "5b4db5c0-e6f8-4208-b981-aafc9c5c23c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label', 'id']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mkCL9b-8hmZ1"
   },
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop(col_obj, axis = 1)\n",
    "y = df[\"label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NfIOX9Lbik_i"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "X, y = sm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5100000, 29)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60NotS9ehbO5"
   },
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scaler = RobustScaler()\n",
    "#scaler.fit(X)\n",
    "# logistic = OneVsRestClassifier(RandomForestClassifier(max_depth=22,n_jobs=-1))\n",
    "#logistic=GaussianNB()\n",
    "#pipe = Pipeline([('normalizer', scaler), ('classifier', logistic)])\n",
    "#pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf1=HistGradientBoostingClassifier(learning_rate=0.1, max_depth= 8, min_samples_leaf=100)\n",
    "clf2=RandomForestClassifier(max_depth=15,n_jobs=9)\n",
    "eclf1 = VotingClassifier([('gb', clf2),('rf', clf2)], voting='soft',weights=[1,1.5])\n",
    "pipe = Pipeline([('normalizer', scaler), ('classifier', eclf1)])\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pool_train = cb.Pool(X, y)\n",
    "params = {                  # 'task_type':'GPU',\n",
    "                            'iterations':1200,\n",
    "                            'depth':8,\n",
    "                            'random_state':2,\n",
    "                            'learning_rate':0.01,\n",
    "                            'eval_metric':'Recall',\n",
    "                            'loss_function':'MultiCrossEntropy'}\n",
    "clf_with_aux = cb.CatBoostClassifier(**params)\n",
    "clf_with_aux.fit(pool_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predcat = clf_with_aux.predict_proba(X_test)\n",
    "voting = pipe.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "y_pred = ((voting + predcat) / 2).argmax(axis=1)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "parametrs = {\n",
    "              'max_depth': range (1,35),\n",
    "            }\n",
    "grid = GridSearchCV(RandomForestClassifier(), parametrs, scoring='roc_auc', cv=2,n_jobs=9) \n",
    "grid.fit(X_test, y_test) \n",
    "grid.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pkl_filename = \"model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(pipe, file)\n",
    "\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nb_classifier = GaussianNB()\n",
    "\n",
    "params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "gs_NB = GridSearchCV(estimator=nb_classifier, \n",
    "                 param_grid=params_NB, \n",
    "                 cv=2,   # use any cross validation technique \n",
    "                 verbose=1, \n",
    "                 scoring='roc_auc') \n",
    "gs_NB.fit(X_train, y_train)\n",
    "\n",
    "gs_NB.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gb_grid_params = {'learning_rate': [0.1, 0.05, 0.02, 0.01],\n",
    "              'max_depth': [4, 6, 8],\n",
    "              'min_samples_leaf': [20, 50,100,150],\n",
    "              #'max_features': [1.0, 0.3, 0.1] \n",
    "              }\n",
    "print(gb_grid_params)\n",
    "\n",
    "gb_gs = HistGradientBoostingClassifier()\n",
    "\n",
    "clf = GridSearchCV(gb_gs,\n",
    "                               gb_grid_params,\n",
    "                               cv=2,\n",
    "                               scoring='roc_auc',\n",
    "                               verbose = 3, \n",
    "                               n_jobs=2);\n",
    "clf.fit(X_train, y_train);\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейронка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "import tensorflow as tf \n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(1000,activation='sigmoid',input_shape=(29,)))\n",
    "    model.add(layers.Dense(2,activation='sigmoid'))\n",
    "    model.add(layers.Dense(1,activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop',# Вы также можете указать параметры для оптимизатора через optimizer = optimizer.RMSprop (lr = 0.001)\n",
    "                  loss='binary_crossentropy', # Эквивалент потерь = loss.binary_crossentropy\n",
    "                  metrics=[tf.keras.metrics.AUC()]) # Эквивалентно метрике = [metircs.binary_accuracy]\n",
    "    return model\n",
    "model = build_model()\n",
    "\n",
    "\n",
    "history = model.fit(X, y,\n",
    "                    epochs=2, # Итерировать 20 раз по полному набору данных\n",
    "                    batch_size=512,\n",
    "                    class_weight={1:1,0:0.9},\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictions = model.predict(X_test)\n",
    "pred=[]\n",
    "for i in predictions:\n",
    "    pred.append(round(float(i)))\n",
    "print('нейронка',classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "48                |?                 |units_l1\n",
      "True              |?                 |bias_l1\n",
      "relu              |?                 |act_l1\n",
      "48                |?                 |units_l2\n",
      "False             |?                 |bias_l2\n",
      "tanh              |?                 |act_l2\n",
      "adam              |?                 |optimizer\n",
      "\n",
      "Epoch 1/3\n",
      "9961/9961 [==============================] - 27s 3ms/step - loss: 0.4512 - mean_squared_error: 1.8911 - auc: 0.4994 - val_loss: 0.4396 - val_mean_squared_error: 2.1409 - val_auc: 0.5000\n",
      "Epoch 2/3\n",
      "9961/9961 [==============================] - 26s 3ms/step - loss: 0.4396 - mean_squared_error: 2.3565 - auc: 0.5000 - val_loss: 0.4396 - val_mean_squared_error: 2.3751 - val_auc: 0.5000\n",
      "Epoch 3/3\n",
      "9961/9961 [==============================] - 27s 3ms/step - loss: 0.4396 - mean_squared_error: 2.3749 - auc: 0.5000 - val_loss: 0.4396 - val_mean_squared_error: 2.3751 - val_auc: 0.5000\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'binary_crossentropy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m     23\u001b[0m tuner1 \u001b[38;5;241m=\u001b[39m  RandomSearch(hypermodel\u001b[38;5;241m=\u001b[39mbuild_model,\n\u001b[1;32m     24\u001b[0m                       objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m                       \u001b[38;5;66;03m#objective=Objective(name=\"val_mean_squared_error\",direction=\"min\"),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m                       overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     30\u001b[0m                     )\n\u001b[0;32m---> 32\u001b[0m \u001b[43mtuner1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py:203\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m         tuner_utils\u001b[38;5;241m.\u001b[39mvalidate_trial_results(\n\u001b[1;32m    197\u001b[0m             results, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuner.run_trial()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    198\u001b[0m         ),\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mupdate_trial(\n\u001b[1;32m    200\u001b[0m             trial\u001b[38;5;241m.\u001b[39mtrial_id,\n\u001b[1;32m    201\u001b[0m             \u001b[38;5;66;03m# Convert to dictionary before calling `update_trial()`\u001b[39;00m\n\u001b[1;32m    202\u001b[0m             \u001b[38;5;66;03m# to pass it from gRPC.\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m             \u001b[43mtuner_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_metrics_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m                \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moracle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    207\u001b[0m             step\u001b[38;5;241m=\u001b[39mtuner_utils\u001b[38;5;241m.\u001b[39mget_best_step(results, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective),\n\u001b[1;32m    208\u001b[0m         )\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras_tuner/engine/tuner_utils.py:266\u001b[0m, in \u001b[0;36mconvert_to_metrics_dict\u001b[0;34m(results, objective)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# List of multiple exectuion results to be averaged.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# Check this case first to deal each case individually to check for errors.\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m average_metrics_dicts(\n\u001b[0;32m--> 266\u001b[0m         [convert_to_metrics_dict(elem, objective) \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[1;32m    267\u001b[0m     )\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# Single value.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, np\u001b[38;5;241m.\u001b[39mfloating)):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras_tuner/engine/tuner_utils.py:266\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# List of multiple exectuion results to be averaged.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# Check this case first to deal each case individually to check for errors.\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m average_metrics_dicts(\n\u001b[0;32m--> 266\u001b[0m         [\u001b[43mconvert_to_metrics_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[1;32m    267\u001b[0m     )\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# Single value.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, np\u001b[38;5;241m.\u001b[39mfloating)):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras_tuner/engine/tuner_utils.py:279\u001b[0m, in \u001b[0;36mconvert_to_metrics_dict\u001b[0;34m(results, objective)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# A History.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results, keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mHistory):\n\u001b[0;32m--> 279\u001b[0m     best_value, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_get_best_value_and_best_epoch_from_history\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_value\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras_tuner/engine/tuner_utils.py:250\u001b[0m, in \u001b[0;36m_get_best_value_and_best_epoch_from_history\u001b[0;34m(history, objective)\u001b[0m\n\u001b[1;32m    248\u001b[0m best_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch, metrics \u001b[38;5;129;01min\u001b[39;00m epoch_metrics\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 250\u001b[0m     objective_value \u001b[38;5;241m=\u001b[39m \u001b[43mobjective\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;66;03m# Support multi-objective.\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m objective\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m metrics:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras_tuner/engine/objective.py:55\u001b[0m, in \u001b[0;36mObjective.get_value\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, logs):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;124;03m\"\"\"Get the objective value from the metrics logs.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m        The objective value.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlogs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'binary_crossentropy'"
     ]
    }
   ],
   "source": [
    "from keras_tuner import RandomSearch\n",
    "from keras_tuner import Objective\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import tensorflow as tf \n",
    "def build_model(hyperparams):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=(X.shape[1],)))\n",
    "    model.add(layers.Dense(units=hyperparams.Int(\"units_l1\", 16, 50, step=16),\n",
    "                           use_bias=hyperparams.Boolean(\"bias_l1\"),\n",
    "                           activation=hyperparams.Choice(\"act_l1\", [\"relu\", \"tanh\",'sigmoid'])\n",
    "                          ))\n",
    "    model.add(layers.Dense(units=hyperparams.Int(\"units_l2\", 16, 50, step=16),\n",
    "                           use_bias=hyperparams.Boolean(\"bias_l2\"),\n",
    "                           activation=hyperparams.Choice(\"act_l2\", [\"relu\", \"tanh\",'sigmoid'])\n",
    "                          ))\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    optim=hyperparams.Choice(\"optimizer\",[\"sgd\",\"rmsprop\",\"adam\"])\n",
    "    model.compile(optim, loss=\"binary_crossentropy\", metrics=[\"mean_squared_error\",tf.keras.metrics.AUC()])\n",
    "\n",
    "    return model\n",
    "tuner1 =  RandomSearch(hypermodel=build_model,\n",
    "                      objective=\"binary_crossentropy\",\n",
    "                      #objective=Objective(name=\"val_mean_squared_error\",direction=\"min\"),\n",
    "                      max_trials=100,\n",
    "                      #seed=123,\n",
    "                      project_name=\"Regression\",\n",
    "                      overwrite=True\n",
    "                    )\n",
    "\n",
    "tuner1.search(X_train, y_train, batch_size=512, epochs=3, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'units_l1': 48,\n",
       " 'bias_l1': True,\n",
       " 'act_l1': 'sigmoid',\n",
       " 'units_l2': 32,\n",
       " 'bias_l2': False,\n",
       " 'act_l2': 'sigmoid',\n",
       " 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = tuner1.get_best_hyperparameters()\n",
    "\n",
    "best_params[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 48)                1440      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1536      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,009\n",
      "Trainable params: 3,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner1.get_best_models()[0]\n",
    "\n",
    "best_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28125/28125 [==============================] - 22s 766us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gennalll/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gennalll/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gennalll/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "нейронка               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99    874353\n",
      "           1       0.00      0.00      0.00     25647\n",
      "\n",
      "    accuracy                           0.97    900000\n",
      "   macro avg       0.49      0.50      0.49    900000\n",
      "weighted avg       0.94      0.97      0.96    900000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = best_model.predict(X_test)\n",
    "pred=[]\n",
    "for i in predictions:\n",
    "    pred.append(round(float(i)))\n",
    "print('нейронка',classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейронка 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikeras[tensorflow] in /home/gennalll/.local/lib/python3.8/site-packages (0.9.0)\n",
      "Requirement already satisfied: packaging>=0.21 in /home/gennalll/.local/lib/python3.8/site-packages (from scikeras[tensorflow]) (21.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /home/gennalll/.local/lib/python3.8/site-packages (from scikeras[tensorflow]) (1.1.1)\n",
      "Requirement already satisfied: tensorflow>=2.7.0; extra == \"tensorflow\" in /home/gennalll/.local/lib/python3.8/site-packages (from scikeras[tensorflow]) (2.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/gennalll/.local/lib/python3.8/site-packages (from packaging>=0.21->scikeras[tensorflow]) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/gennalll/.local/lib/python3.8/site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.23.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/gennalll/.local/lib/python3.8/site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.8.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/gennalll/.local/lib/python3.8/site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/gennalll/.local/lib/python3.8/site-packages (from scikit-learn>=1.0.0->scikeras[tensorflow]) (3.1.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (1.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (2.0.7)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (1.48.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (3.7.0)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (14.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (3.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (3.19.4)\n",
      "Requirement already satisfied: setuptools in /home/gennalll/.local/lib/python3.8/site-packages (from tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (65.3.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (0.27.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (2.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (4.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (1.14.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/gennalll/.local/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (2.11.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/gennalll/.local/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (2.2.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/gennalll/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/gennalll/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/gennalll/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/gennalll/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/gennalll/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (4.12.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/gennalll/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/gennalll/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/gennalll/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/gennalll/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (2022.6.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/gennalll/.local/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/gennalll/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/gennalll/.local/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (3.2.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/gennalll/.local/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow>=2.7.0; extra == \"tensorflow\"->scikeras[tensorflow]) (3.8.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikeras[tensorflow]\n",
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def create_baseline():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(60, input_dim=29, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.AUC()])\n",
    "\treturn model\n",
    "\n",
    "estimator = KerasClassifier(model=create_baseline, epochs=1, batch_size=512, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=41, shuffle=True, random_state=42)\n",
    "results = cross_val_score(estimator, X, y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model2=create_baseline()\n",
    "model2.fit(X, y)\n",
    "model2.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predictions = model2.predict(X_test)\n",
    "pred=[]\n",
    "for i in predictions:\n",
    "    pred.append(round(float(i)))\n",
    "print('нейронка',classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предсказание "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data=pd.read_csv('test_dataset_test.csv',low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"priority\"] = pd.Categorical(df[\"priority\"])\n",
    "df[\"priority\"].astype('category').cat.codes\n",
    "df[\"priority\"] = df[\"priority\"].cat.codes\n",
    "df[\"is_in_yandex\"] = pd.Categorical(df[\"is_in_yandex\"])\n",
    "df[\"is_in_yandex\"].astype('category').cat.codes\n",
    "df[\"is_in_yandex\"] = df[\"is_in_yandex\"].cat.codes\n",
    "df[\"is_return\"] = pd.Categorical(df[\"is_return\"])\n",
    "df[\"is_return\"].astype('category').cat.codes\n",
    "df[\"is_return\"] = df[\"is_return\"].cat.codes\n",
    "df[\"oper_type + oper_attr\"] = pd.Categorical(df[\"oper_type + oper_attr\"])\n",
    "df[\"oper_type + oper_attr\"].astype('category').cat.codes\n",
    "df[\"oper_type + oper_attr\"] = df[\"oper_type + oper_attr\"].cat.codes\n",
    "df[\"index_oper\"] = pd.Categorical(df[\"index_oper\"])\n",
    "df[\"index_oper\"].astype('category').cat.codes\n",
    "df[\"index_oper\"] = df[\"index_oper\"].cat.codes\n",
    "df[\"type\"] = pd.Categorical(df[\"type\"])\n",
    "df[\"type\"].astype('category').cat.codes\n",
    "df[\"type\"] = df[\"type\"].cat.codes\n",
    "df[\"is_privatecategory\"] = pd.Categorical(df[\"is_privatecategory\"])\n",
    "df[\"is_privatecategory\"].astype('category').cat.codes\n",
    "df[\"is_privatecategory\"] = df[\"is_privatecategory\"].cat.codes\n",
    "df[\"name_mfi\"] = pd.Categorical(df[\"name_mfi\"])\n",
    "df[\"name_mfi\"].astype('category').cat.codes\n",
    "df[\"name_mfi\"] = df[\"name_mfi\"].cat.codes\n",
    "df[\"weight\"] = round(df[\"weight\"]/1000)\n",
    "df['is_wrong']=df['is_wrong_sndr_name']+df['is_wrong_rcpn_name']+df['is_wrong_phone_number']+df['is_wrong_address']\n",
    "df['total_mean']=df['total_qty_over_index_and_type']/df['total_qty_over_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['id'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pred_data['label']=pipe.predict(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pred_data[['id','label']].to_csv('bestmodel.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейро "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(df)\n\u001b[1;32m      2\u001b[0m pred\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m predictions:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(df)\n",
    "pred=[]\n",
    "for i in predictions:\n",
    "    pred.append(round(float(i)))\n",
    "pred_data['label']=pred\n",
    "pred_data[['id','label']].to_csv('bestmodelnero.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
